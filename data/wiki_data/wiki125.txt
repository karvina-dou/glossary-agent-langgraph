Static random-access memory(static RAMorSRAM) is a type ofrandom-access memory(RAM) that useslatching circuitry (flip-flop)to store each bit. SRAM isvolatile memory; data is lost when power is removed.
Thestaticqualifier differentiates SRAM fromdynamicrandom-access memory(DRAM):
Semiconductor bipolar SRAM was invented in 1963 by Robert Norman atFairchild Semiconductor.Metal–oxide–semiconductorSRAM (MOS-SRAM) was invented in 1964 by John Schmidt at Fairchild Semiconductor. The first device was a 64-bit MOS p-channel SRAM.
SRAM was the main driver behind any newCMOS-based technology fabrication process since the 1960s, when CMOS was invented.
In 1964, Arnold Farber and Eugene Schlig, working for IBM, created a hard-wired memory cell, using atransistorgate andtunnel diodelatch. They replaced the latch with two transistors and tworesistors, a configuration that became known as the Farber-Schlig cell. That year they submitted an invention disclosure, but it was initially rejected.In 1965, Benjamin Agusta and his team at IBM created a 16-bit silicon memory chip based on the Farber-Schlig cell, with 84 transistors, 64 resistors, and 4 diodes.
In April 1969, Intel Inc. introduced its first product, Intel 3101, a SRAM memory chip intended to replace bulkymagnetic-core memorymodules; Its capacity was 64 bitsand was based onbipolar junction transistors.It was designed by usingrubylith.
Though it can be characterized asvolatile memory, SRAM exhibitsdata remanence.
SRAM offers a simple data access model and does not require a refresh circuit. Performance and reliability are good and power consumption is low when idle. Since SRAM requires more transistors per bit to implement, it is less dense and more expensive than DRAM and also has a higherpower consumptionduring read or write access. The power consumption of SRAM varies widely depending on how frequently it is accessed.
Many categories of industrial and scientific subsystems, automotive electronics, and similarembedded systems, contain SRAM which, in this context, may be referred to asESRAM.Some amount (kilobytes or less) is also embedded in practically all modern appliances, toys, etc. that implement an electronic user interface.
SRAM in itsdual-portedform is sometimes used for real-timedigital signal processingcircuits.
SRAM is also used in personal computers, workstations, routers and peripheral equipment: CPUregister files, internalCPU caches, internalGPU cachesand externalburst modeSRAM caches,hard diskbuffers,routerbuffers, etc.LCD screensandprintersalso normally employ SRAM to hold the image displayed (or to be printed). LCDs can have SRAM in their LCD controllers. SRAM was used for the main memory of many early personal computers such as theZX80,TRS-80 Model 100, andVIC-20.
Some earlymemory cardsin the late 1980s to early 1990s used SRAM as a storage medium, which required a lithium battery to keep the contents of the SRAM.
SRAM may be integrated on chip for:
Hobbyists, specifically home-built processor enthusiasts,often prefer SRAM due to the ease of interfacing. It is much easier to work with than DRAM as there are no refresh cycles and the address and data buses are often directly accessible.In addition to buses and power connections, SRAM usually requires only three controls: Chip Enable (CE), Write Enable (WE) and Output Enable (OE). In synchronous SRAM, Clock (CLK) is also included.
Non-volatile SRAM(nvSRAM) has standard SRAM functionality, but they save the data when the power supply is lost, ensuring preservation of critical information. nvSRAMs are used in a wide range of situations – networking, aerospace, and medical, among many others– where the preservation of data is critical and where batteries are impractical.
Pseudostatic RAM(PSRAM) is DRAM combined with a self-refresh circuit.It appears externally as slower SRAM, albeit with a density and cost advantage over true SRAM, and without the access complexity of DRAM.
In the 1990s, asynchronous SRAM used to be employed for fast access time. Asynchronous SRAM was used asmain memoryfor small cache-less embedded processors used in everything fromindustrial electronicsandmeasurement systemstohard disksand networking equipment, among many other applications. Nowadays, synchronous SRAM (e.g. DDR SRAM) is rather employed similarly to synchronous DRAM –DDR SDRAMmemory is rather used thanasynchronous DRAM. Synchronous memory interface is much faster as access time can be significantly reduced by employingpipelinearchitecture. Furthermore, as DRAM is much cheaper than SRAM, SRAM is often replaced by DRAM, especially in the case when a large volume of data is required. SRAM memory is, however, much faster for random (not block / burst) access. Therefore, SRAM memory is mainly used forCPU cache, small on-chip memory,FIFOsor other small buffers.
A typical SRAM cell is made up of sixMOSFETs, and is often called a6TSRAM cell. Eachbitin the cell is stored on fourtransistors(M1, M2, M3, M4) that form two cross-coupled inverters. This storage cell has two stable states which are used to denote 0 and 1. Two additionalaccesstransistors serve to control the access to a storage cell during read and write operations. 6T SRAM is the most common kind of SRAM.In addition to 6T SRAM, other kinds of SRAM use 4, 5, 7,8, 9,10(4T, 5T, 7T 8T, 9T, 10T SRAM), or more transistors per bit.Four-transistor SRAM is quite common in stand-alone SRAM devices (as opposed to SRAM used for CPU caches), implemented in special processes with an extra layer ofpolysilicon, allowing for very high-resistance pull-up resistors.The principal drawback of using 4T SRAM is increasedstatic powerdue to the constant current flow through one of the pull-down transistors (M1 or M2).
This is sometimes used to implement more than one (read and/or write) port, which may be useful in certain types ofvideo memoryandregister filesimplemented with multi-ported SRAM circuitry.
Generally, the fewer transistors needed per cell, the smaller each cell can be. Since the cost of processing a silicon wafer is relatively fixed, using smaller cells and so packing more bits on one wafer reduces the cost per bit of memory.
Memory cells that use fewer than four transistors are possible; however, such 3Tor 1T cells are DRAM, not SRAM (even the so-called1T-SRAM).
Access to the cell is enabled by the word line (WL in figure) which controls the twoaccesstransistors M5and M6in 6T SRAM figure (or M3and M4in 4T SRAM figure) which, in turn, control whether the cell should be connected to the bit lines:BLand BL. They are used to transfer data for both read and write operations. Although it is not strictly necessary to have two bit lines, both the signal and its inverse are typically provided in order to improvenoise marginsand speed.
During read accesses, the bit lines are actively driven high and low by the inverters in the SRAM cell. This improves SRAM bandwidth compared to DRAMs –  in a DRAM, the bit line is connected to storage capacitors andcharge sharingcauses the bit line to swing upwards or downwards. The symmetric structure of SRAMs also allows fordifferential signaling, which makes small voltage swings more easily detectable. Another difference with DRAM that contributes to making SRAM faster is that commercial chips accept all address bits at a time. By comparison, commodity DRAMs have the address multiplexed in two halves, i.e. higher bits followed by lower bits, over the same package pins in order to keep their size and cost down.
The size of an SRAM withmaddress lines andndata lines is2words, or2×nbits.  The most common word size is 8 bits, meaning that a single byte can be read or written to each of2different words within the SRAM chip.  Several common SRAM chips have 11 address lines (thus a capacity of2= 2,048 =2kwords) and an 8-bit word, so they are referred to as2k × 8 SRAM.
The dimensions of an SRAM cell on an IC is determined by theminimum feature sizeof the process used to make the IC.
An SRAM cell has three states:
SRAM operating in read and write modes should havereadabilityandwrite stability, respectively. The three different states work as follows:
If the word line is not asserted, theaccesstransistors M5and M6disconnect the cell from the bit lines. The two cross-coupled inverters formed by M1– M4will continue to reinforce each other as long as they are connected to the supply.
In theory, reading only requires asserting the word line WL and reading the SRAM cell state by a single access transistor and bit line, e.g. M6, BL. However, bit lines are relatively long and have largeparasitic capacitance. To speed up reading, a more complex process is used in practice: The read cycle is started by precharging both bit lines BL andBL, to high (logic1) voltage. Then asserting the word line WL enables both the access transistors M5and M6, which causes one bit line BL voltage to slightly drop. Then the BL andBLlines will have a small voltage difference between them. A sense amplifier will sense which line has the higher voltage and thus determine whether there was 1 or 0 stored. The higher the sensitivity of the sense amplifier, the faster the read operation. As the NMOS is more powerful, the pull-down is easier. Therefore, bit lines are traditionally precharged to high voltage. Many researchers are also trying to precharge at a slightly low voltage to reduce the power consumption.
The write cycle begins by applying the value to be written to the bit lines. To write a 0, a 0 is applied to the bit lines, such as settingBLto 1 and BL to 0. This is similar to applying a reset pulse to anSR-latch, which causes the flip flop to change state. A1is written by inverting the values of the bit lines. WL is then asserted and the value that is to be stored is latched in. This works because the bit line input-drivers are designed to be much stronger than the relatively weak transistors in the cell itself so they can easily override the previous state of the cross-coupled inverters. In practice, access NMOS transistors M5and M6have to be stronger than either bottom NMOS (M1, M3) or top PMOS (M2, M4) transistors. This is easily obtained as PMOS transistors are much weaker than NMOS when same sized. Consequently, when one transistor pair (e.g.  M3and M4) is only slightly overridden by the write process, the opposite transistors pair (M1and M2) gate voltage is also changed. This means that the M1and M2transistors can be easier overridden, and so on. Thus, cross-coupled inverters magnify the writing process.
RAMwith an access time of 70 ns will output valid data within 70 ns from the time that the address lines are valid. Some SRAM cells have apage mode, where words of a page (256, 512, or 1024 words) can be read sequentially with a significantly shorter access time (typically approximately 30 ns). The page is selected by setting the upper address lines and then words are sequentially read by stepping through the lower address lines.
Over 30 years (from 1987 to 2017), with a steadily decreasingtransistor size(node size), the footprint-shrinking of the SRAM cell topology itself slowed down, making it harder to pack the cells more densely.One of the reasons is that scaling down transistor size leads to SRAM reliability issues. Careful cells designs are necessary to achieve SRAM cells that do not suffer from stability problems especially when they are being read.With the introduction of theFinFETtransistor implementation of SRAM cells, they started to suffer from increasing inefficiencies in cell sizes.
Besides issues with size a significant challenge of modern SRAM cells is a static current leakage. The current, that flows from positive supply (Vdd), through the cell, and to the ground, increases exponentially when the cell's temperature rises. The cell power drain occurs in both active and idle states, thus wasting useful energy without any useful work done. Even though in the last 20 years the issue was partially addressed by the Data Retention Voltage technique (DRV) with reduction rates ranging from 5 to 10, the decrease in node size caused reduction rates to fall to about 2.
With these two issues it became more challenging to develop energy-efficient and dense SRAM memories, prompting semiconductor industry to look for alternatives such asSTT-MRAMandF-RAM.
In 2019 a French institute reported on a research of anIoT-purposed28nmfabricatedIC.It was based onfully depleted silicon on insulator-transistors (FD-SOI), had two-ported SRAM memory rail for synchronous/asynchronous accesses, and selectivevirtual ground(SVGND). The study claimed reaching an ultra-low SVGND current in asleepand read modes by finely tuning its voltage.